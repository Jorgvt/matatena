[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Matatena",
    "section": "",
    "text": "Knucklebones is a simple game in which a dice is rolled and one of the two players must place it in their corresponding board. Each player can only choose the column in which the dice is placed, and if any dice is already placed in that column, the following is put behind. If there are more than one dice with the same number, their score is added and then multiplied by the number of times it appears. For example, if a column has two 6s, their values add up to 24, but if a column has a 6 and a 5, the total score would be 11.\n\nThe basic board is a 3x3 grid."
  },
  {
    "objectID": "core.html#calculating-the-score",
    "href": "core.html#calculating-the-score",
    "title": "Matatena",
    "section": "Calculating the score",
    "text": "Calculating the score\n\nsource\n\nGame.score\n\n Game.score (player)\n\nReturns the calculated score for a player. If there are numbers repeated in a column, their values must be added and multiplied by the number of repetitions. Otherwise, they are added. If there are repreated and non-repeated in the same column, the repeated are summed and multiplied by the number of repetitions and then the result is added to the non-repeated.\n\n\n\n\nDetails\n\n\n\n\nplayer\nNumber of the player we want to calculate the score.\n\n\n\n\nmatatena = Game()\nmatatena.boards[0] = np.array([[1,0,0],\n                               [1,2,3],\n                               [4,2,5]])\nassert matatena.score(0) == 8+8+8\n\nNow that we know how to calculate the score, we can patch the __repr__ method of our class to show the score of each player as well:\n\nmatatena = Game()\nassert not matatena.is_done()\nmatatena\n\nPlayer 1 (0.0) *\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\nPlayer 2 (0.0)\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n\n\n\nmatatena = Game()\nmatatena\n\nPlayer 1 (0.0) | Player 2 (0.0) *\n[[0. 0. 0.]    | [[0. 0. 0.]     \n [0. 0. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]"
  },
  {
    "objectID": "core.html#full-turn",
    "href": "core.html#full-turn",
    "title": "Matatena",
    "section": "Full turn",
    "text": "Full turn\nA full turn in a Matatena game must follow the following steps:\n\nCheck the current player\nDraw a random dice\nPlace the dice in a column\n\nCheck if the column is not full -> The dice can be placed (If it can’t be placed the game is ended)\n\nChange the current player to the next one in the list\nRepeat\n\n\nsource\n\nGame.play_turn\n\n Game.play_turn ()\n\nPlays a full turn.\n\nmatatena = Game()\nprint(matatena.current_player)\nmatatena.play_turn()\n# The player is asked for an input and the rolled dice is placed\n# in the chosen column.\nprint(matatena.current_player)\nmatatena\n\n0\nDice to place: 6\nPlayer 1 (0.0) * | Player 2 (0.0)\n[[0. 0. 0.]      | [[0. 0. 0.]   \n [0. 0. 0.]      |  [0. 0. 0.]   \n [0. 0. 0.]]     |  [0. 0. 0.]]  \n0\n\n\nPlayer 1 (6.0) * | Player 2 (0.0)\n[[6. 0. 0.]      | [[0. 0. 0.]   \n [0. 0. 0.]      |  [0. 0. 0.]   \n [0. 0. 0.]]     |  [0. 0. 0.]]"
  },
  {
    "objectID": "exceptions.html",
    "href": "exceptions.html",
    "title": "Custom exceptions",
    "section": "",
    "text": "source\n\nColumnFullError\nRaised when trying to put a dice in a column that is already full."
  },
  {
    "objectID": "gym.html",
    "href": "gym.html",
    "title": "Gym Environment",
    "section": "",
    "text": "They remind us to add the metadata attribute to specify the render-mode (human, rgb_array or ansi) and the framerate. Every environment should support the render-mode None, and you don’t need to add it explicitly.\nAs we have almost defined the environment completelly before, we don’t need to add a lot of information to this class (we can inherit from the one we defined before); but we have to explicitly define the attributes self.observation_space and self.action_space.\n\nself.action_space: Our agents can only choose them column in which they want to place the dice, so our action space is going to be restricted to a number between 0 and 2 (assuming the board has 3 columns, but could depend on it directly).\nself.observation_space: What does an agent see? It makes sense to provide all the information available: Its current board, the opponent’s board and the dice it has to place. We can implement this easily with a spaces.Dict. The different boards can be encoded as spaces.Box with dtype=np.uint8 so that they are discrete environments by with an array-like shape. It should work very similarly with a spaces.MultiDiscrete environment for example.\n\n\nsource\n\nMatatenaEnv\n\n MatatenaEnv (*args, **kwds)\n\ngym-ready implementation of Game.\n\nmatatena = MatatenaEnv()\nmatatena\n\nPlayer 1 (0.0) | Player 2 (0.0) *\n[[0. 0. 0.]    | [[0. 0. 0.]     \n [0. 0. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]    \n\n\n\nmatatena.observation_space.sample()\n\nOrderedDict([('agent',\n              array([[2, 0, 3],\n                     [1, 3, 0],\n                     [5, 5, 3]], dtype=uint8)),\n             ('dice', 1),\n             ('opponent',\n              array([[1, 1, 2],\n                     [6, 6, 4],\n                     [3, 2, 0]], dtype=uint8))])\n\n\n\nmatatena.action_space.sample()\n\n0\n\n\n\n\nReset\nThe reset method will be called to initiate a new episode. It should be called as well when a done signal is issued by the environment to reset it. It must accept a reset parameter.\nIt is recommended to use the random generator included when inheriting from gym.Env(self.np_random), but we need to remember to call super().reset(seed=seed) to make sure that the environment is seeded correctly.\nFinally, it must return a tuple of the initial observation and some auxiliary information (which will be None in our case).\n\nsource\n\nMatatenaEnv.reset\n\n MatatenaEnv.reset (seed:int=None, options=None)\n\nReinitializes the environment and returns the initial state.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nseed\nint\nNone\nSeed to control the RNG.\n\n\noptions\nNoneType\nNone\nAdditional options.\n\n\n\n\nmatatena = MatatenaEnv()\nmatatena\n\nPlayer 1 (0.0) | Player 2 (0.0) *\n[[0. 0. 0.]    | [[0. 0. 0.]     \n [0. 0. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]    \n\n\n\nmatatena.reset()\n\n({'agent': array([[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]),\n  'opponent': array([[0., 0., 0.],\n         [0., 0., 0.],\n         [0., 0., 0.]]),\n  'dice': 3},\n None)\n\n\n\nmatatena\n\nPlayer 1 (0.0) | Player 2 (0.0) *\n[[0. 0. 0.]    | [[0. 0. 0.]     \n [0. 0. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]    \n\n\n\n\n\nStep\nThe .step() method contains the logic of the environment. Must accept an action, compute the state of the environment after applying the action and return a 4-tuple: (observation, reward, done, info).\n\nIn our case, the action should be the column in which the agent wants to place the rolled dice.\n\n\nsource\n\nMatatenaEnv.step\n\n MatatenaEnv.step (action)\n\nRun one timestep of the environment’s dynamics.\nWhen end of episode is reached, you are responsible for calling :meth:reset to reset this environment’s state. Accepts an action and returns either a tuple (observation, reward, terminated, truncated, info), or a tuple (observation, reward, done, info). The latter is deprecated and will be removed in future versions.\nArgs: action (ActType): an action provided by the agent\nReturns: observation (object): this will be an element of the environment’s :attr:observation_space. This may, for instance, be a numpy array containing the positions and velocities of certain objects. reward (float): The amount of reward returned as a result of taking the action. terminated (bool): whether a terminal state (as defined under the MDP of the task) is reached. In this case further step() calls could return undefined results. truncated (bool): whether a truncation condition outside the scope of the MDP is satisfied. Typically a timelimit, but could also be used to indicate agent physically going out of bounds. Can be used to end the episode prematurely before a terminal state is reached. info (dictionary): info contains auxiliary diagnostic information (helpful for debugging, learning, and logging). This might, for instance, contain: metrics that describe the agent’s performance state, variables that are hidden from observations, or individual reward terms that are combined to produce the total reward. It also can contain information that distinguishes truncation and termination, however this is deprecated in favour of returning two booleans, and will be removed in a future version.\n(deprecated)\ndone (bool): A boolean value for if the episode has ended, in which case further :meth:`step` calls will return undefined results.\n    A done signal may be emitted for different reasons: Maybe the task underlying the environment was solved successfully,\n    a certain timelimit was exceeded, or the physics simulation has entered an invalid state.\n\n\n\n\n\n\n\n\nDetails\n\n\n\n\naction\nAction to be executed on the environment. Should be the column in which the agent wants to place the dice.\n\n\n\n\n\n\nRender\n\nLastly, only rendering the environment is left.\n\nAs we have previously built a quite decent __repr__ method, we are going to only use that one. It would be nice to get something nicer runnig with PyGame, tho.\n\nsource\n\nMatatenaEnv.render\n\n MatatenaEnv.render ()\n\nCompute the render frames as specified by render_mode attribute during initialization of the environment.\nThe set of supported modes varies per environment. (And some third-party environments may not support rendering at all.) By convention, if render_mode is:\n\nNone (default): no render is computed.\nhuman: render return None. The environment is continuously rendered in the current display or terminal. Usually for human consumption.\nsingle_rgb_array: return a single frame representing the current state of the environment. A frame is a numpy.ndarray with shape (x, y, 3) representing RGB values for an x-by-y pixel image.\nrgb_array: return a list of frames representing the states of the environment since the last reset. Each frame is a numpy.ndarray with shape (x, y, 3), as with single_rgb_array.\nansi: Return a list of strings (str) or StringIO.StringIO containing a terminal-style text representation for each time step. The text can include newlines and ANSI escape sequences (e.g. for colors).\n\nNote: Rendering computations is performed internally even if you don’t call render(). To avoid this, you can set render_mode = None and, if the environment supports it, call render() specifying the argument ‘mode’.\nNote: Make sure that your class’s metadata ‘render_modes’ key includes the list of supported modes. It’s recommended to call super() in implementations to use the functionality of this method.\n\n\n\nUsage\n\nSimple usage examples.\n\n\nenv = MatatenaEnv()\nobs, info = env.reset()\nenv.render()\nprint(f\"Rolled dice is: {obs['dice']}\")\n\nPlayer 1 (0.0) | Player 2 (0.0) *\n[[0. 0. 0.]    | [[0. 0. 0.]     \n [0. 0. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]    \nRolled dice is: 4\n\n\n\naction = env.action_space.sample()\nprint(f\"Placing the dice in column: {action}\")\nobs, reward, done, info = env.step(action)\nenv.render()\n\nPlacing the dice in column: 1\nPlayer 1 (0.0) * | Player 2 (4.0)\n[[0. 0. 0.]      | [[0. 4. 0.]   \n [0. 0. 0.]      |  [0. 0. 0.]   \n [0. 0. 0.]]     |  [0. 0. 0.]]  \n\n\nWe can even perform a full game:\n\nenv = MatatenaEnv()\nobs, info = env.reset()\ndone = False\n\nwhile not done:\n    action = env.action_space.sample()\n    obs, reward, done, info = env.step(action)\n    env.render()\nif info is not None: \n    print(info)\n\nPlayer 1 (0.0) * | Player 2 (1.0)\n[[0. 0. 0.]      | [[0. 1. 0.]   \n [0. 0. 0.]      |  [0. 0. 0.]   \n [0. 0. 0.]]     |  [0. 0. 0.]]  \nPlayer 1 (3.0) | Player 2 (1.0) *\n[[0. 3. 0.]    | [[0. 1. 0.]     \n [0. 0. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]    \nPlayer 1 (3.0) * | Player 2 (3.0)\n[[0. 3. 0.]      | [[2. 1. 0.]   \n [0. 0. 0.]      |  [0. 0. 0.]   \n [0. 0. 0.]]     |  [0. 0. 0.]]  \nPlayer 1 (8.0) | Player 2 (3.0) *\n[[0. 3. 0.]    | [[2. 1. 0.]     \n [0. 5. 0.]    |  [0. 0. 0.]     \n [0. 0. 0.]]   |  [0. 0. 0.]]    \nPlayer 1 (8.0) * | Player 2 (5.0)\n[[0. 3. 0.]      | [[2. 1. 0.]   \n [0. 5. 0.]      |  [0. 2. 0.]   \n [0. 0. 0.]]     |  [0. 0. 0.]]  \nPlayer 1 (13.0) | Player 2 (5.0) *\n[[5. 3. 0.]     | [[2. 1. 0.]     \n [0. 5. 0.]     |  [0. 2. 0.]     \n [0. 0. 0.]]    |  [0. 0. 0.]]    \nPlayer 1 (13.0) * | Player 2 (9.0)\n[[5. 3. 0.]       | [[2. 1. 0.]   \n [0. 5. 0.]       |  [0. 2. 0.]   \n [0. 0. 0.]]      |  [0. 4. 0.]]  \nPlayer 1 (19.0) | Player 2 (9.0) *\n[[5. 3. 0.]     | [[2. 1. 0.]     \n [0. 5. 0.]     |  [0. 2. 0.]     \n [0. 6. 0.]]    |  [0. 4. 0.]]    \nPlayer 1 (19.0) * | Player 2 (15.0)\n[[5. 3. 0.]       | [[2. 1. 0.]    \n [0. 5. 0.]       |  [2. 2. 0.]    \n [0. 6. 0.]]      |  [0. 4. 0.]]   \nPlayer 1 (19.0) * | Player 2 (15.0)\n[[5. 3. 0.]       | [[2. 1. 0.]    \n [0. 5. 0.]       |  [2. 2. 0.]    \n [0. 6. 0.]]      |  [0. 4. 0.]]   \nTerminated -> column full"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "matatena",
    "section": "",
    "text": "pip install matatena"
  }
]